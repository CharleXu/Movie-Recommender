{
    "nbformat_minor": 1, 
    "cells": [
        {
            "source": "## Load Data", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 1, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "from pyspark.sql.types import *\nimport pyspark.sql.functions as F"
        }, 
        {
            "execution_count": 2, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "+------+-------+------+\n|userId|movieId|rating|\n+------+-------+------+\n|     1|     31|   2.5|\n|     1|   1029|   3.0|\n|     1|   1061|   3.0|\n|     1|   1129|   2.0|\n|     1|   1172|   4.0|\n+------+-------+------+\nonly showing top 5 rows\n\n"
                }
            ], 
            "source": "# The code was removed by DSX for sharing."
        }, 
        {
            "execution_count": 3, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "execution_count": 3, 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "StructType(List(StructField(userId,StringType,true),StructField(movieId,StringType,true),StructField(rating,StringType,true)))"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "small_ratings_df.schema"
        }, 
        {
            "execution_count": 4, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "execution_count": 4, 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "['userId', 'movieId', 'rating']"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "small_ratings_df.schema.names"
        }, 
        {
            "execution_count": 8, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "StructType(List(StructField(userId,IntegerType,true),StructField(movieId,IntegerType,true),StructField(rating,DoubleType,true)))\n"
                }
            ], 
            "source": "# convert datatype\n\nfrom pyspark.sql.types import IntegerType\nfrom pyspark.sql.types import DoubleType\n\nsmall_ratings_df = small_ratings_df.withColumn(\"userId\", small_ratings_df[\"userId\"].cast(IntegerType()))\nsmall_ratings_df = small_ratings_df.withColumn(\"movieId\", small_ratings_df[\"movieId\"].cast(IntegerType()))\nsmall_ratings_df = small_ratings_df.withColumn(\"rating\", small_ratings_df[\"rating\"].cast(DoubleType()))\n\nprint(small_ratings_df.schema)"
        }, 
        {
            "execution_count": 12, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "+-------+--------------------+\n|movieId|               title|\n+-------+--------------------+\n|      1|    Toy Story (1995)|\n|      2|      Jumanji (1995)|\n|      3|Grumpier Old Men ...|\n|      4|Waiting to Exhale...|\n|      5|Father of the Bri...|\n+-------+--------------------+\nonly showing top 5 rows\n\nStructType(List(StructField(movieId,IntegerType,true),StructField(title,StringType,true)))\n"
                }
            ], 
            "source": "small_movies_df = spark.read\\\n  .format('org.apache.spark.sql.execution.datasources.csv.CSVFileFormat')\\\n  .option('header', 'true')\\\n  .load(cos.url('movies.csv', 'moiverecommendationd136f4f785054be6861fc3dba4e8391e')).drop('genres')\n\nsmall_movies_df = small_movies_df.withColumn(\"movieId\", small_movies_df[\"movieId\"].cast(IntegerType()))\n\nsmall_movies_df.show(5)\nprint(small_movies_df.schema)"
        }, 
        {
            "source": "## Collaborative Filtering", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 14, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "train, validation, test = small_ratings_df.randomSplit([0.6, 0.2, 0.2])\nvalidation_for_predict = validation.select(validation.columns[0:2])\ntest_for_predict = test.select(test.columns[0:2])"
        }, 
        {
            "execution_count": 23, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "For rank 4 the RMSE is 0.9352785533511581\nFor rank 8 the RMSE is 0.9461427592255386\nFor rank 12 the RMSE is 0.9464846239958269\nThe best model was trained with rank 4\n"
                }
            ], 
            "source": "from pyspark.mllib.recommendation import ALS\nimport math\n\n# set parameters\nseed = 0\niterations = 10\nregularization_parameter = 0.1\nranks = [4, 8, 12]\nerrors = [0, 0, 0]\nerr = 0\ntolerance = 0.02\n\nmin_error = float('inf')\nbest_rank = -1\nbest_iteration = -1\n\n# find the best rank\nfor rank in ranks:\n    model = ALS.train(train, rank, seed=seed, iterations=iterations, lambda_=regularization_parameter)\n    predictions = model.predictAll(validation_for_predict.rdd).map(lambda x: ((x[0], x[1]), x[2]))\n    rates_and_preds = validation.rdd.map(lambda x: ((x[0], x[1]), x[2])).join(predictions)\n    error = math.sqrt(rates_and_preds.map(lambda x: (x[1][0] - x[1][1])**2).mean())\n    errors[err] = error\n    err += 1\n    print('For rank %s the RMSE is %s'%(rank, error))\n    if error < min_error:\n        min_error = error\n        best_rank = rank\n    \nprint('The best model was trained with rank %s' % best_rank)"
        }, 
        {
            "source": "### Load Full Data", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 49, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "StructType(List(StructField(userId,IntegerType,true),StructField(movieId,IntegerType,true),StructField(rating,DoubleType,true)))\n+------+-------+------+\n|userId|movieId|rating|\n+------+-------+------+\n|     1|    110|   1.0|\n|     1|    147|   4.5|\n|     1|    858|   5.0|\n|     1|   1221|   5.0|\n|     1|   1246|   5.0|\n+------+-------+------+\nonly showing top 5 rows\n\n"
                }
            ], 
            "source": "full_ratings_df = spark.read\\\n  .format('org.apache.spark.sql.execution.datasources.csv.CSVFileFormat')\\\n  .option('header', 'true')\\\n  .load(cos.url('ratings_full.csv', 'moiverecommendationd136f4f785054be6861fc3dba4e8391e'))\\\n  .drop('timestamp')\n\n\nfull_ratings_df = full_ratings_df.withColumn(\"userId\", full_ratings_df[\"userId\"].cast(IntegerType()))\nfull_ratings_df = full_ratings_df.withColumn(\"movieId\", full_ratings_df[\"movieId\"].cast(IntegerType()))\nfull_ratings_df = full_ratings_df.withColumn(\"rating\", full_ratings_df[\"rating\"].cast(DoubleType()))\n\nprint(full_ratings_df.schema)\nfull_ratings_df.show(5)"
        }, 
        {
            "execution_count": 91, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "+-------+--------------------+\n|movieId|               title|\n+-------+--------------------+\n|      1|    Toy Story (1995)|\n|      2|      Jumanji (1995)|\n|      3|Grumpier Old Men ...|\n|      4|Waiting to Exhale...|\n|      5|Father of the Bri...|\n+-------+--------------------+\nonly showing top 5 rows\n\n"
                }
            ], 
            "source": "full_movies_df = spark.read\\\n  .format('org.apache.spark.sql.execution.datasources.csv.CSVFileFormat')\\\n  .option('header', 'true')\\\n  .load(cos.url('movies_full.csv', 'moiverecommendationd136f4f785054be6861fc3dba4e8391e')).drop('genres')\n\nfull_movies_df = full_movies_df.withColumn(\"movieId\", full_movies_df[\"movieId\"].cast(IntegerType()))\nfull_movies_df.show(5)\nfull_movies_df.createOrReplaceTempView(\"full_movies_df_view\")\nfull_movies_titles = full_movies_df.rdd.map(lambda x: (int(x[0]),x[1]))"
        }, 
        {
            "execution_count": 33, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "For testing data the RMSE is 0.8326700962589142\n"
                }
            ], 
            "source": "full_train_df, full_test_df = full_ratings_df.randomSplit([0.7, 0.3])\nfull_model = ALS.train(full_train_df, best_rank, seed=seed, iterations=iterations, lambda_=regularization_parameter)\n\nX = full_test_df.rdd.map(lambda x: (x[0], x[1]))\ny_hat = full_model.predictAll(X).map(lambda x: ((x[0], x[1]), x[2]))\nrates_and_preds = full_test_df.rdd.map(lambda x: ((x[0], x[1]), x[2])).join(y_hat)\nerror = math.sqrt(rates_and_preds.map(lambda x: (x[1][0] - x[1][1])**2).mean())\n\nprint('For testing data the RMSE is %s' %error)"
        }, 
        {
            "execution_count": 50, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "from pyspark.sql import SparkSession\n\nspark = SparkSession \\\n    .builder \\\n    .appName(\"Python Spark SQL\") \\\n    .config(\"spark.some.config.option\", \"some-value\") \\\n    .getOrCreate()"
        }, 
        {
            "execution_count": 80, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "full_ratings_df.cache()\nfull_ratings_df.createOrReplaceTempView(\"full_ratings_df_view\")\n\n# calulate average ratings for each movie id\nd_avgRating_df = spark.sql(\"SELECT movieID, AVG(rating) AS avg_rating FROM full_ratings_df_view GROUP BY movieID\")\n# calculate number of ratings for each movie id\nid_count_df = spark.sql(\"SELECT movieID, count(*) AS count FROM full_ratings_df_view GROUP BY movieID\")\n\nid_avgRating_df.createOrReplaceTempView(\"id_avgRating_df_view\")\nid_count_df.createOrReplaceTempView('id_count_df_view')"
        }, 
        {
            "source": "## Add New User Ratings and Retrain the Model", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 82, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "New user ratings: [(0, 260, 4), (0, 1, 3), (0, 16, 3), (0, 25, 4), (0, 32, 4), (0, 335, 1), (0, 379, 1), (0, 296, 3), (0, 858, 5), (0, 50, 4)]\n"
                }
            ], 
            "source": "new_user_ID = 0\n\n# The format of each line is (userID, movieID, rating)\nnew_user_ratings = [\n     (0,260,4), # Star Wars (1977)\n     (0,1,3), # Toy Story (1995)\n     (0,16,3), # Casino (1995)\n     (0,25,4), # Leaving Las Vegas (1995)\n     (0,32,4), # Twelve Monkeys (a.k.a. 12 Monkeys) (1995)\n     (0,335,1), # Flintstones, The (1994)\n     (0,379,1), # Timecop (1994)\n     (0,296,3), # Pulp Fiction (1994)\n     (0,858,5) , # Godfather, The (1972)\n     (0,50,4) # Usual Suspects, The (1995)\n    ]\n\nnew_user_ratings_rdd = sc.parallelize(new_user_ratings)\nprint('New user ratings: %s' % new_user_ratings_rdd.take(10))"
        }, 
        {
            "execution_count": 85, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# add ratings of the new user to our data\nnew_ratings_rdd = full_ratings_df.rdd.union(new_user_ratings_rdd)"
        }, 
        {
            "execution_count": 107, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "New model trained in 92.379 seconds\n"
                }
            ], 
            "source": "from time import time\n\nt0 = time()\n# retrain our model\nnew_ratings_model = ALS.train(new_ratings_rdd, rank=8, seed=seed, \n                              iterations=iterations, lambda_=regularization_parameter)\ntt = time() - t0\n\nprint(\"New model trained in %s seconds\" % round(tt,3))"
        }, 
        {
            "execution_count": 112, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "execution_count": 112, 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "[(6656, ((1.0458995363624215, 'Attack of the Puppet People (1958)'), 47)),\n (119808, ((2.9503873804552105, 'Arizona Colt Returns (1970)'), 1)),\n (4160,\n  ((2.9357647226700676,\n    'Widow of St. Pierre, The (Veuve de Saint-Pierre, La) (2000)'),\n   366))]"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "new_user_ratings_ids = map(lambda x: x[1], new_user_ratings) # get just movie IDs\n\n# keep just those not on the ID list (thanks Lei Li for spotting the error!)\nnew_user_unrated_movies_rdd = (full_movies_df.rdd.filter(lambda x: x[0] not in new_user_ratings_ids).map(lambda x: (new_user_ID, x[0])))\n\n# Use the input RDD, new_user_unrated_movies_RDD, with new_ratings_model.predictAll() to predict new ratings for the movies\nnew_user_recommendations_rdd = new_ratings_model.predictAll(new_user_unrated_movies_RDD)\n\n# Transform new_user_recommendations_RDD into pairs of the form (Movie ID, Predicted Rating)\nnew_user_recommendations_rating_rdd = new_user_recommendations_rdd.map(lambda x: (x.product, x.rating))\nnew_user_recommendations_rating_title_and_count_rdd = new_user_recommendations_rating_rdd.join(full_movies_titles).join(id_count_df.rdd)\nnew_user_recommendations_rating_title_and_count_rdd.take(3)"
        }, 
        {
            "execution_count": 113, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "TOP recommended movies (with more than 25 reviews):\n(\"Long Night's Journey Into Day (2000)\", 4.067201180445796, 35)\n('Heimat - A Chronicle of Germany (Heimat - Eine deutsche Chronik) (1984)', 4.037841937716027, 32)\n('Tale of Tales (Skazka skazok) (1979)', 3.967847257853708, 39)\n('Godfather, The (1972)', 3.9641593171048726, 57070)\n('Human Condition III, The (Ningen no joken III) (1961)', 3.8950607000338264, 82)\n('Godfather: Part II, The (1974)', 3.8945976991324662, 36679)\n('Frozen Planet (2011)', 3.873168757489889, 322)\n('Alone in the Wilderness (2004)', 3.857246927303845, 326)\n('Harakiri (Seppuku) (1962)', 3.84499029188689, 610)\n('Madagascar (2011)', 3.838933093129907, 26)\n('Walking with Monsters (2005)', 3.8358965744744227, 28)\n('Civil War, The (1990)', 3.8341200476173682, 400)\n(\"Sundays and Cybele (Les dimanches de Ville d'Avray) (1962)\", 3.8196692796561083, 28)\n('Seven Samurai (Shichinin no samurai) (1954)', 3.812708140982135, 13994)\n('Planet Earth (2006)', 3.808814825168765, 754)\n('Dr. Strangelove or: How I Learned to Stop Worrying and Love the Bomb (1964)', 3.8027136378978725, 28280)\n('I, Claudius (1976)', 3.7992986243276228, 63)\n('Not on Your Life (Verdugo, El) (Executioner, The) (1963)', 3.795561460655031, 26)\n('The War (2007)', 3.7753706716749567, 44)\n('Island, The (a.k.a. Naked Island) (Hadaka no shima) (1960)', 3.759245583470604, 29)\n('Yojimbo (1961)', 3.7567446000753115, 4155)\n('Pulp Fiction (1994)', 3.7519432496244605, 87901)\n('Decalogue, The (Dekalog) (1989)', 3.751785056488351, 520)\n('Apocalypse Now (1979)', 3.749754189729703, 27741)\n('Rocks (Das Rad) (2003)', 3.7492404514142983, 33)\n"
                }
            ], 
            "source": "new_user_recommendations_rating_title_and_count_rdd = new_user_recommendations_rating_title_and_count_rdd.map(lambda r: (r[1][0][1], r[1][0][0], r[1][1]))\n    \ntop_movies = new_user_recommendations_rating_title_and_count_rdd.filter(lambda r: r[2]>=25).takeOrdered(25, key=lambda x: -x[1])\n\nprint ('TOP recommended movies (with more than 25 reviews):\\n%s' % '\\n'.join(map(str, top_movies)))"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": ""
        }
    ], 
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.5 with Spark 2.1", 
            "name": "python3-spark21", 
            "language": "python"
        }, 
        "language_info": {
            "mimetype": "text/x-python", 
            "nbconvert_exporter": "python", 
            "version": "3.5.4", 
            "name": "python", 
            "file_extension": ".py", 
            "pygments_lexer": "ipython3", 
            "codemirror_mode": {
                "version": 3, 
                "name": "ipython"
            }
        }
    }, 
    "nbformat": 4
}